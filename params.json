{"name":"OpenStreeMaps Raleigh, NC Data Wrangling With MongoDB","tagline":"OSM data extract of Raleigh Area has been cleaned and loaded into MongoDB instance for analysis","body":"## Background\r\nUsing a [Open Street Maps](https://www.openstreetmap.org) extract of Raleigh, NC from [MapZen](https://s3.amazonaws.com/metro-extracts.mapzen.com/raleigh_north-carolina.osm.bz2), data munging techniques - such as assessing the quality of the data for validity, accuracy, completeness, consistency and uniformity - were used to clean the OpenStreetMap data and were loaded into a MongoDB instance. MongoDB queries were then run to analyze the data. The data validation and audit was performed in Python. The code and other extracts can be downloaded using the 'Download .zip' link above.\r\n\r\n## Problems Encountered in the Map\r\nAfter initially downloading a small sample size of the Raleigh data and running it against a provisional data.py file, I noticed three main problems with the data, which I will discuss in the following order:\r\n* _Multiple streets for a node:_ A university like NCSU has multiple streets in it. But the street keys aren’t of the form “addr:street”. In such cases, the data is still cleaned for the streets but they are not added to an address dictionary value. Instead, the keys are kept as is.\r\n* _Relation nodes:_ There are some nodes who have element names as ‘Relation’. They are handled in a similar way as ways and nodes.\r\n* _Postal codes:_ There are a lot of postal codes which don’t pertain to Raleigh, NC. Some investigation is done around it to find out the root cause.\r\n\r\n### **Multiple streets for a node **\r\nThere are some tags which contain field values like “Street_1” and “Street_2”. They seem be the adjoining streets of a building and hence the attributes are kept as they are. \r\n\r\n### **Postal codes**\r\nRaleigh postal codes are in this range - 27587, 27601, 27605, 27608, 27609, 27612, 27613, 27614, 27615, 27616.[3] The database contains a lot of other values though. A lot of postal codes don’t refer to Raleigh, NC but the surrounding areas. \r\n\r\n```\r\n>>> x_post_code = db.data.aggregate([{\"$match\":{\"address.postcode\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$address.postcode\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":1}}])\r\n>>> list_post = list(x_post_code)\r\n>>> for i in list_post: print i['_id']\r\n```\r\nA subset of the results is shown here:\r\n27612-7156\r\n27612-3326\r\n27519-6205\r\n27511-5928\r\n\r\nIn the above list, many postal codes like 27519, 27511 are not in Raleigh. \r\nA query to find the list of cities confirms it too.\r\n\r\n```\r\n>>> x_city = db.data.aggregate([{\"$match\":{\"address.city\":{\"$exists\":1}}}, {\"$group\":{\"_id\":\"$address.city\", \"count\":{\"$\r\n>>> x_city_l = list(x_city)\r\n>>> x_city_l\r\n[{u'count': 1, u'_id': u'cary'}, {u'count': 1, u'_id': u'Ra'}, {u'count': 1, u'_id': u'Apex'}, {u'count': 2, u'_id': u'W\r\nake Forest'}, {u'count': 2, u'_id': u'durham'}, {u'count': 2, u'_id': u'chapel Hill'}, {u'count': 2, u'_id': u'raleigh'}\r\n, {u'count': 108, u'_id': u'Morrisville'}, {u'count': 236, u'_id': u'Chapel Hill'}, {u'count': 279, u'_id': u'Carrboro'}\r\n, {u'count': 885, u'_id': u'Raleigh'}, {u'count': 1295, u'_id': u'Durham'}, {u'count': 1745, u'_id': u'Cary'}]\r\n```\r\nCities like Apex and Morrisville which are around Raleigh are also included in this extract. So the data gives info of Raleigh and its surrounding areas.\r\n\r\n## Data Overview\r\nThis section contains basic statistics about the dataset and the MongoDB queries used to gather them.\r\n                                                \r\n#### File sizes\r\nraleigh_north-carolina.osm……………………………………… 518045444 Bytes \r\n\r\n```\r\n# Finding out the file size\r\n>>> import os\r\n>>> statinfo = os.stat('new-york_new-york.osm')\r\n>>> print statinfo.st_size\r\n518045444\r\n```\r\n\r\nThe following are the counts of the various node types in the input file:\r\n```\r\n{'bounds': 1,\r\n 'member': 7683,\r\n 'nd': 2829895,\r\n 'node': 2564072,\r\n 'osm': 1,\r\n 'relation': 741,\r\n 'tag': 819970,\r\n 'way': 216498}\r\n```\r\n\r\nExploration of the data has been done to prevent issues while loading the data in MongoDB. The result is the following:\r\n```\r\n{'lower': 498201, 'lower_colon': 276537, 'other': 45231, 'problemchars': 1}\r\n```\r\nThe above categories have been formed by comparing the key value to various regular expressions written in the code leading to the above result.\r\n\r\n#### Number of documents\r\n```\r\n>>> db.data.find().count()\r\n2781311\r\n```\r\n\r\n#### Number of nodes\r\n```\r\n>>> db.data.find({\"type\":\"node\"}).count()\r\n2564072\r\n```\r\n\r\n#### Number of ways\r\n```\r\n>>> db.data.find({\"type\":\"way\"}).count()\r\n216498\r\n```\r\n\r\n#### Number of relations\r\n```\r\n>>> db.data.find({\"type\":\"relation\"}).count()\r\n741\r\n```\r\n\r\n#### Number of unique users                                                \r\n```\r\n>>> len(db.data.distinct(\"created.user\"))\r\n724\r\n```\r\n\r\n#### Top 1 contributing user\r\n```\r\n>>> x = db.data.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}}, {\"$limit\":1}])\r\n>>> print list(x)\r\n[{u'count': 2136690, u'_id': u'jumbanho'}]\r\n```\r\n\r\n#### Number of users appearing only once (having 1 post)\r\n```\r\n>>> x = db.data.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$group\":{\"_id\":\"$count\", \"num_users\r\n\":{\"$sum\":1}}}, {\"$sort\":{\"_id\":1}}, {\"$limit\":1}])\r\n>>> print list(x)\r\n[{u'num_users': 150, u'_id': 1}]\r\n```\r\n\r\n## Additional Ideas\r\n### **Contributor statistics and gamification suggestion**\r\nFew users contribute to the most data which suggests automated entry of some admin. Here are some statistics:\r\n* Top user contribution percentage (“jumbanho”) – 76.82%\r\n* Top user contribution percentage (“jumbanho”) – 76.82%\r\n\r\nIt is clear that the contribution of the top 10 users is too high as compared to the total number of users (724). If some incentives are given to the users to contribute more, it will help spur the data entry process and will also provide more quality to the data. \r\n\r\n### **Additional data exploration using MongoDB queries**\r\n#### Top 10 appearing amenities\r\n```\r\n>>> amenity_list = list(db.data.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}},{\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$s\r\num\":1}}},{\"$sort\":{\"count\":-1}},{\"$limit\":10}]))\r\n>>> amenity_list\r\n\r\n[{u'count': 1935, u'_id': u'parking'}, {u'count': 551, u'_id': u'place_of_worship'}, {u'count': 523, u'_id': u'bicycle_p\r\narking'}, {u'count': 499, u'_id': u'restaurant'}, {u'count': 254, u'_id': u'fast_food'}, {u'count': 227, u'_id': u'schoo\r\nl'}, {u'count': 205, u'_id': u'fuel'}, {u'count': 130, u'_id': u'bench'}, {u'count': 112, u'_id': u'bank'}, {u'count': 1\r\n08, u'_id': u'swimming_pool'}]          \r\n```\r\n\r\n#### Top 10 appearing shops                          \r\n```\r\n>>> shop_list = list(db.data.aggregate([{\"$match\":{\"shop\":{\"$exists\":1}}},{\"$group\":{\"_id\":\"$shop\",\"count\":{\"$sum\":1}}},\r\n{\"$sort\":{\"count\":-1}},{\"$limit\":10}]))\r\n>>>\r\n>>> shop_list\r\n[{u'count': 147, u'_id': u'convenience'}, {u'count': 117, u'_id': u'supermarket'}, {u'count': 94, u'_id': u'clothes'}, {\r\nu'count': 57, u'_id': u'car_repair'}, {u'count': 56, u'_id': u'hairdresser'}, {u'count': 52, u'_id': u'vacant'}, {u'coun\r\nt': 46, u'_id': u'mall'}, {u'count': 36, u'_id': u'department_store'}, {u'count': 36, u'_id': u'beauty'}, {u'count': 27,\r\n u'_id': u'jewelry'}]\r\n```\r\n\r\n#### Most popular supermarkets\r\n```\r\n>>> supermarket_list = list(db.data.aggregate([{\"$match\":{\"shop\":{\"$exists\":1},\"shop\":\"supermarket\"}},{\"$group\":{\"_id\":\"\r\n$name\",\"count\":{\"$sum\":1}}},{\"$sort\":{\"count\":-1}},{\"$limit\":2}]))\r\n>>> supermarket_list\r\n[{u'count': 22, u'_id': u'Food Lion'}, {u'count': 22, u'_id': u'Harris Teeter'}]\r\n```\r\n\r\n## Conclusion\r\nAfter this review of the data it’s obvious that the Raleigh area data is incomplete, though I believe it has been well cleaned for the purposes of this exercise. It interests me to notice a fair amount of GPS data makes it into OpenStreetMap.org on account of users’ efforts, whether by scripting a map editing bot or otherwise. With a rough GPS data processor in place and working together with a more robust data processor similar to code.py, I think it would be possible to input a great amount of cleaned data to OpenStreetMap.org.\r\n\r\n## References\r\n1. http://stackoverflow.com/questions/2104080/how-to-check-file-size-in-python\r\n2. http://stackoverflow.com/questions/30333020/mongodb-pymongo-aggregate-gives-strange-output-something-about-cursor\r\n3. http://www.city-data.com/zipmaps/Raleigh-North-Carolina.html#ixzz3kIKkAXfLA\r\n\r\n## Author\r\nThe above project was done as part of the 'Data Analayst Nanodegree' by Roshan Shetty. Please contact me on rosshanabshetty@gmail.com for any doubts, queries or information.","google":"UA-67244594-1","note":"Don't delete this file! It's used internally to help with page regeneration."}